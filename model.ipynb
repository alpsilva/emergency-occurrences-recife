{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"hora_minuto\":  str,\n",
    "    \"municipio\": \"category\",\n",
    "    \"bairro\": \"category\",\n",
    "    \"endereco\": \"category\",\n",
    "    \"origem_chamado\": \"category\",\n",
    "    \"tipo\": \"category\",\n",
    "    \"subtipo\": \"category\",\n",
    "    \"sexo\": \"category\",\n",
    "    \"idade\": float,\n",
    "    \"motivo_finalizacao\": \"category\",\n",
    "    \"motivo_desfecho\": \"category\",\n",
    "}\n",
    "\n",
    "columns_to_datetime = [\"data\"]\n",
    "\n",
    "raw_df = pd.read_csv(\"./datasets/ocorrencias2022.csv\", sep=';', dtype=dtypes, parse_dates=columns_to_datetime)\n",
    "raw_df['hora_minuto'] = pd.to_datetime(raw_df['hora_minuto']).dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando dados vazios e inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.drop(\"motivo_finalizacao\", axis=1)\n",
    "raw_df = raw_df.dropna(subset=[\"municipio\", \"bairro\", \"subtipo\", \"sexo\", \"idade\"])\n",
    "\n",
    "def older_than_120(age: int):\n",
    "  if age >= 120:\n",
    "    return 120\n",
    "  return age\n",
    "\n",
    "raw_df[\"idade\"] = raw_df[\"idade\"].apply(lambda x : older_than_120(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motivos_desfecho = raw_df['motivo_desfecho'].value_counts()\n",
    "motivos_desfecho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propósito do modelo\n",
    "\n",
    "Quando um chamado é iniciado, a maior partes das informações é recolhida na hora. O motivo do desfecho, contudo, só pode ser preenchido após o encerramento do chamado. Destacamos os seguintes motivos de desfecho:\n",
    "\n",
    "\"PACIENTE JÉ ENCONTRADO EM ÓBITO\"\n",
    "\n",
    "\"ÓBITO DURANTE O ATENDIMENTO\"\n",
    "\n",
    "Partimos do pressuposto de que alguns desses casos de óbito poderiam ser evitados com maior agilidade ou priorização por parte do SAMU.\n",
    "\n",
    "Daí veio a idéia do nosso modelo:\n",
    "\n",
    "Um modelo capaz de determinar com certo grau de certeza, baseando-se nos detalhes recolhidos na hora do registro da ocorrência, se aquela ocorrência corre risco de terminar com algum óbito. Caso ela afirme positivamente, essa informação poderia ser usada para maior priorização ou agilidade por parte da equipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do dataset de treino\n",
    "\n",
    "1. Inicialmente, iremos criar uma coluna de \"obito\" mais simples, que engloba os 2 tipos de motivo de desfecho que levaram a óbitos, é composta por 1 ou 0, em caso de óito ou o contrário.\n",
    "\n",
    "2. Após isso, removeremos a coluna \"motivo_desfecho\", pois, como discutido, ela só é preenchida após a conclusão da ocorrência, então não faria sentido o modelo ter acesso a essa informação no momento em que analisa uma ocorrência nova.\n",
    "\n",
    "3. Criaremos uma coluna que transforme o dado de hora numa relação mais categórica e genérica, \"Período\", como madrugada, manhã, tarde e noite.\n",
    "\n",
    "4. Removeremos colunas que julgamos serem irrelevantes para a classificação, como data e colunas de endereço. Decidimos manter a coluna de hora_minuto pois é argumentável que a hora que algo ocorre pode impactar na conclusão.\n",
    "\n",
    "4. Para utilização do scikit learn, utilizaremos a técnica One Hot Enconding para transformar cada tipo categórico em um formato mais desejável para o scikit learn.\n",
    "É importante ressaltar que os dados categóricos \"Período\" e \"Idade\" são ordinais, isso é, uma certa ordem pode ser determinada entre as categorias (manhã vem antes da tarde que vem antes da noite, 55 anos vem antes dos 56 anos), porém o resto das colunas representam dados nominais.\n",
    "\n",
    "5. Por fim, separamos os datasets para treino e verificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['obito'] = [1 if x == \"PACIENTE JÉ ENCONTRADO EM ÓBITO\" or x == \"ÓBITO DURANTE O ATENDIMENTO\" else 0 for x in raw_df['motivo_desfecho']]\n",
    "\n",
    "madrugada_upper = time(4, 59, 59)\n",
    "manha_upper = time(11, 59, 59)\n",
    "tarde_upper = time(17, 59, 59)\n",
    "noite_upper = time(23, 59, 59)\n",
    "\n",
    "conditions = [\n",
    "    (raw_df['hora_minuto'] <= madrugada_upper),\n",
    "    ((raw_df['hora_minuto'] > madrugada_upper) & (raw_df['hora_minuto'] <= manha_upper)),\n",
    "    ((raw_df['hora_minuto'] > manha_upper) & (raw_df['hora_minuto'] <= tarde_upper)),\n",
    "    ((raw_df['hora_minuto'] > tarde_upper) & (raw_df['hora_minuto'] <= noite_upper)),\n",
    "]\n",
    "choices = ['madrugada', 'manha', 'tarde', 'noite']\n",
    "raw_df['periodo'] = np.select(conditions, choices, default='indeterminado')\n",
    "\n",
    "relevant_columns = [\n",
    "    \"periodo\",\n",
    "    \"origem_chamado\",\n",
    "    \"tipo\",\n",
    "    \"subtipo\",\n",
    "    \"sexo\",\n",
    "    \"idade\",\n",
    "    \"obito\"\n",
    "]\n",
    "df = raw_df[relevant_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features = [\n",
    "    \"periodo\",\n",
    "    \"origem_chamado\",\n",
    "    \"tipo\",\n",
    "    \"subtipo\",\n",
    "    \"sexo\",\n",
    "]\n",
    "\n",
    "ohe_df = pd.get_dummies(df, prefix=ohe_features, columns=ohe_features)\n",
    "ohe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = list(ohe_df.columns)\n",
    "features.remove('obito')\n",
    "\n",
    "X = ohe_df[features].to_numpy()\n",
    "\n",
    "y = ohe_df['obito'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train count: (69344, 137)\n",
      "y_train count: (69344,)\n",
      "X_test count: (23115, 137)\n",
      "y_test count: (23115,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train count:\", X_train.shape)\n",
    "print(\"y_train count:\", y_train.shape)\n",
    "print(\"X_test count:\", X_test.shape)\n",
    "print(\"y_test count:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção e otimização de modelos\n",
    "\n",
    "Os 4 modelos escolhidos foram:\n",
    "- Naive Bayes (Gaussian)\n",
    "- Random Forest\n",
    "- Decision Tree\n",
    "- Linear SVC\n",
    "\n",
    "Além disso, utilizamos o método GridSearch para otimização dos hiper-parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "labels = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__priors: None\n",
      "clf__var_smoothing: 0.0002310129700083158\n",
      "Stats for optimized GaussianNB\n",
      "Best Score: 0.9818585441927112\n",
      "labels: [0, 1]\n",
      "Precision: [0.98420159 0.61594203]\n",
      "recall: [0.9976618  0.18973214]\n",
      "f1: [0.99088599 0.29010239]\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__priors': [None],\n",
    "    'clf__var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
    "\n",
    "print(\"Stats for optimized GaussianNB\")\n",
    "print(\"Best Score:\", gs_clf.best_score_)\n",
    "pred = gs_clf.predict(X_test)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, pred, labels=labels)\n",
    "print(\"labels:\", labels)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "print(\"f1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 3: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 4: Linear SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
